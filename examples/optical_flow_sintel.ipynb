{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import local_models.local_models\n",
    "import local_models.algorithms\n",
    "import local_models.utils\n",
    "import local_models.linear_projections\n",
    "import local_models.loggin\n",
    "import local_models.TLS_models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model\n",
    "import sklearn.cluster\n",
    "from importlib import reload\n",
    "from ml_battery.utils import cmap\n",
    "import matplotlib as mpl\n",
    "import sklearn.datasets\n",
    "import sklearn.decomposition\n",
    "import logging\n",
    "import ml_battery.log\n",
    "import time\n",
    "import os\n",
    "import mayavi\n",
    "import mayavi.mlab\n",
    "import matplotlib.image as img\n",
    "\n",
    "\n",
    "import subprocess\n",
    "#on headless systems, tmux: \"Xvfb :1 -screen 0 1280x1024x24 -auth localhost\", then \"export DISPLAY=:1\" in the jupyter tmux\n",
    "mayavi.mlab.options.offscreen = True\n",
    "\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#reload(local_models.local_models)\n",
    "#reload(lm)\n",
    "#reload(local_models.loggin)\n",
    "#reload(local_models.TLS_models)\n",
    "np.warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_shit():\n",
    "    import local_models.local_models\n",
    "    import local_models.algorithms\n",
    "    import local_models.utils\n",
    "    import local_models.linear_projections\n",
    "    import local_models.loggin\n",
    "    import local_models.TLS_models\n",
    "    import numpy as np\n",
    "    import logging\n",
    "    import ml_battery.log\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    #reload(local_models.local_models)\n",
    "    #reload(lm)\n",
    "    #reload(local_models.loggin)\n",
    "    #reload(local_models.TLS_models)\n",
    "    np.warnings.filterwarnings('ignore')\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRESH=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names = {\n",
    "    local_models.local_models.GaussianKernel: 'gaussian',\n",
    "    local_models.local_models.TriCubeKernel: 'tricube'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = [8.0, 8.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2data(image):\n",
    "    return np.concatenate((np.mgrid[0:1:image.shape[0]*1j, 0:1:image.shape[1]*1j], image.reshape(1,*image.shape)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "class Everything(object):\n",
    "    def __eq__(*args): return True\n",
    "\n",
    "# data is time, y, x, intensity\n",
    "imgs = []\n",
    "previous_dims = Everything()\n",
    "for i, im_path in enumerate(glob.glob(\"../data/sintel/training/clean/alley_1/*.png\")):\n",
    "    image = np.average(img.imread(im_path), axis=2)\n",
    "    dims = image.shape\n",
    "    if not dims==previous_dims:\n",
    "        raise BaseException(\"must all be same shape\")\n",
    "    previous_dims = dims\n",
    "    imgs.append(np.concatenate((np.ones([1] + list(image.shape[:2]))*i, img2data(image))))\n",
    "data = np.stack(imgs, axis=3)\n",
    "data[0,:,:,:] /= i\n",
    "gridder = local_models.utils.Grid2Vec()\n",
    "data = gridder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22323200, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL=local_models.local_models.GaussianKernel\n",
    "RUN = 1\n",
    "\n",
    "project_dir = \"../data/sintel_alley1_{}_{:03d}\".format(kernel_names[KERNEL], RUN)\n",
    "#project_dir = \"../data/3dscene_{}\".format(kernel_names[KERNEL])\n",
    "\n",
    "os.makedirs(project_dir, exist_ok=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_flo(f_name):\n",
    "    with open(f_name, 'rb') as f:\n",
    "        magic = np.fromfile(f, np.float32, count=1)\n",
    "        if 202021.25 != magic:\n",
    "            raise BaseException(\"invalid flo file {}\".format(f_name))\n",
    "        else:\n",
    "            w = np.fromfile(f, np.int32, count=1)[0]\n",
    "            h = np.fromfile(f, np.int32, count=1)[0]\n",
    "            data = np.fromfile(f, np.float32, count=2*w*h)\n",
    "            # Reshape data into 3D array (columns, rows, bands)\n",
    "            data2D = np.resize(data, (h, w, 2))\n",
    "    return data2D\n",
    "\n",
    "def EPE(flo1, flo2):\n",
    "    return np.average(np.linalg.norm(flo1-flo2, axis=2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<local_models.local_models.LocalModels at 0x7ffa6a373be0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_models = local_models.local_models.LocalModels(local_models.TLS_models.LinearODR_mD(3))\n",
    "linear_models.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDWIDTH = 0.03\n",
    "pth = os.path.join(project_dir, \"bandwidth_{:08.03f}\".format(BANDWIDTH))\n",
    "os.makedirs(pth, exist_ok=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n",
      "(100, 4)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-a84cb1e65edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mFRESH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mjoblib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mconvergededs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverge_n_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBANDWIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mconvergededs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def converge_n_save(bandwidth, i, data):\n",
    "    logger = import_shit()\n",
    "    logger.info(\"stuff!\")\n",
    "    for converged in local_models.algorithms.local_tls_shift_till_convergence(linear_models, data, tol=1e-8,\n",
    "                                         kernel=KERNEL(bandwidth),\n",
    "                                         report=False):\n",
    "        pass\n",
    "    logger.info(\"batch {:05d} complete\")\n",
    "    np.savetxt(os.path.join(pth, \"converged{:08d}.dat\".format(i)), converged)\n",
    "    return None\n",
    "\n",
    "def batcher(data, size):\n",
    "    for i in range(0, data.shape[0], size):\n",
    "        batch = data[i:i+size]\n",
    "        print(batch.shape)\n",
    "        yield batch\n",
    "    \n",
    "if FRESH:\n",
    "    from joblib import Parallel, delayed\n",
    "    convergededs = Parallel(n_jobs=32)(delayed(converge_n_save)(BANDWIDTH, i, batch) for i, batch in enumerate(batcher(data, 100)))\n",
    "else:\n",
    "    convergededs = []\n",
    "    for i, bandwidth in enumerate(bandwidths):\n",
    "        convergededs.append(np.loadtxt(os.path.join(pth, \"converged{:08.02f}.dat\".format(bandwidth))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_center(data, weights=None):\n",
    "    return data - np.average(data, axis=0,weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, bandwidth in enumerate(bandwidths):\n",
    "    converged = convergededs[i]\n",
    "    data_avg = np.average(converged, axis=0)\n",
    "    data_std = np.std(converged, axis=0)\n",
    "    figure = mayavi.mlab.figure(figure=None, bgcolor=(1,1,1), fgcolor=(0,0,0), engine=None, size=(1000, 500))\n",
    "    #mayavi.mlab.surf(grid[0], grid[1], kde_wireframe/z_scale, colormap='Greys', opacity=1)\n",
    "    nodes = mayavi.mlab.points3d(converged[:,0], converged[:,1], converged[:,2], \n",
    "                                 scale_mode='scalar', colormap='gist_earth')\n",
    "    nodes.glyph.scale_mode = 'scale_by_vector'\n",
    "    nodes.mlab_source.dataset.point_data.vectors = np.ones((converged.shape[0],3))*(np.average(data_std)/400)\n",
    "    nodes.mlab_source.dataset.point_data.scalars = (converged[:,1] - (data_avg[1]-3*data_std[1]))/(6*data_std[1])\n",
    "    #bunodes = mayavi.mlab.points3d(data[:,0], data[:,1], data[:,2], scale_mode='scalar', color=(0,1,0))\n",
    "    #bunodes.mlab_source.dataset.point_data.scalars = np.ones(data.shape[0])*0.1\n",
    "\n",
    "\n",
    "    #mayavi.mlab.axes()\n",
    "\n",
    "    #mayavi.mlab.view(views[0][1],views[0][0])\n",
    "    mayavi.mlab.view(azimuth=180, elevation=80, distance=1*np.average(data_avg), focalpoint=(data_avg[0], data_avg[1], data_avg[2]))\n",
    "    mayavi.mlab.move(forward=None, right=0.1*data_avg[1], up=-0.02*data_avg[0])\n",
    "    title = \"converged_data_b{:08.02f}\".format(bandwidth)\n",
    "    mayavi.mlab.savefig(os.path.join(pth, \"{}.png\".format(title)))\n",
    "    mayavi.mlab.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mayavi.mlab.close(all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_pct = 0.2\n",
    "grid_steps = 20\n",
    "data_mins, data_maxes, data_ranges = local_models.linear_projections.min_max_range(data)\n",
    "graph_bounds = local_models.linear_projections.sane_graph_bounds(data_mins, data_maxes, data_ranges, range_pct)\n",
    "\n",
    "grid_limits = tuple(map(lambda i: slice(graph_bounds[0,i], graph_bounds[1,i], grid_steps*1j), range(graph_bounds.shape[1])))\n",
    "grid = np.mgrid[grid_limits]\n",
    "gridder = local_models.utils.Grid2Vec()\n",
    "grid = gridder.fit_transform(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for converged2 in local_models.algorithms.local_tls_shift_till_convergence(linear_models, grid, tol=1e-10,\n",
    "                                     kernel=KERNEL(bandwidth),\n",
    "                                     report=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converged2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = pcl.PointCloud()\n",
    "cloud.from_array(converged2.astype('float32'))\n",
    "#visual = pcl.pcl_visualization.CloudViewing()\n",
    "#visual.ShowMonochromeCloud(cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mayavi.mlab.figure(figure=None, bgcolor=(1,1,1), fgcolor=(0,0,0), engine=None, size=(800, 800))\n",
    "#mayavi.mlab.surf(grid[0], grid[1], kde_wireframe/z_scale, colormap='Greys', opacity=1)\n",
    "nodes = mayavi.mlab.points3d(converged2[:,0], converged2[:,1], converged2[:,2], scale_mode='scalar', color=(1,0,0))\n",
    "nodes.mlab_source.dataset.point_data.scalars = np.ones(converged2.shape[0])*0.1\n",
    "bunodes = mayavi.mlab.points3d(data[:,0], data[:,1], data[:,2], scale_mode='scalar', color=(0,1,0))\n",
    "bunodes.mlab_source.dataset.point_data.scalars = np.ones(data.shape[0])*0.1\n",
    "\n",
    "\n",
    "#mayavi.mlab.axes()\n",
    "\n",
    "#mayavi.mlab.view(views[0][1],views[0][0])\n",
    "data_avg = np.average(converged2, axis=1)\n",
    "mayavi.mlab.view(azimuth=0, elevation=30, distance=1, focalpoint=(data_avg[0], data_avg[1], data_avg[2]))\n",
    "title = \"converged_g000{:05d}\".format(grid_steps)\n",
    "mayavi.mlab.savefig(os.path.join(project_dir, \"{}.png\".format(title)))\n",
    "mayavi.mlab.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
